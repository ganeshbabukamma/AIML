{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uOZe3UO68U-"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Order Delivery Time Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd9e2-HF6_85"
      },
      "source": [
        "## Objectives\n",
        "The objective of this assignment is to build a regression model that predicts the delivery time for orders placed through Porter. The model will use various features such as the items ordered, the restaurant location, the order protocol, and the availability of delivery partners.\n",
        "\n",
        "The key goals are:\n",
        "- Predict the delivery time for an order based on multiple input features\n",
        "- Improve delivery time predictions to optimiae operational efficiency\n",
        "- Understand the key factors influencing delivery time to enhance the model's accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcC6tJ2p7F2p"
      },
      "source": [
        "## Data Pipeline\n",
        "The data pipeline for this assignment will involve the following steps:\n",
        "1. **Data Loading**\n",
        "2. **Data Preprocessing and Feature Engineering**\n",
        "3. **Exploratory Data Analysis**\n",
        "4. **Model Building**\n",
        "5. **Model Inference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGOQI_f72jV1"
      },
      "source": [
        "## Data Understanding\n",
        "The dataset contains information on orders placed through Porter, with the following columns:\n",
        "\n",
        "| Field                     | Description                                                                                 |\n",
        "|---------------------------|---------------------------------------------------------------------------------------------|\n",
        "| market_id                 | Integer ID representing the market where the restaurant is located.                         |\n",
        "| created_at                | Timestamp when the order was placed.                                                        |\n",
        "| actual_delivery_time      | Timestamp when the order was delivered.                                                     |\n",
        "| store_primary_category    | Category of the restaurant (e.g., fast food, dine-in).                                      |\n",
        "| order_protocol            | Integer representing how the order was placed (e.g., via Porter, call to restaurant, etc.). |\n",
        "| total_items               | Total number of items in the order.                                                         |\n",
        "| subtotal                  | Final price of the order.                                                                   |\n",
        "| num_distinct_items        | Number of distinct items in the order.                                                      |\n",
        "| min_item_price            | Price of the cheapest item in the order.                                                    |\n",
        "| max_item_price            | Price of the most expensive item in the order.                                              |\n",
        "| total_onshift_dashers     | Number of delivery partners on duty when the order was placed.                              |\n",
        "| total_busy_dashers        | Number of delivery partners already occupied with other orders.                             |\n",
        "| total_outstanding_orders  | Number of orders pending fulfillment at the time of the order.                              |\n",
        "| distance                  | Total distance from the restaurant to the customer.                                         |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QoCQFDzHUWP"
      },
      "source": [
        "## **Importing Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jun9CeAc7QOw"
      },
      "outputs": [],
      "source": [
        "# Import essential libraries for data manipulation and analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import statsmodels\n",
        "import statsmodels.api as sm\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MueJxkvUIII3"
      },
      "source": [
        "## **1. Loading the data**\n",
        "Load 'porter_data_1.csv' as a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJS8ZRJXHTwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53812b5a-3c64-41a8-9039-8c0fd6379451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab\n"
          ]
        }
      ],
      "source": [
        "# Importing the file porter_data_1.csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab\n",
        "Delivery_time_Data=pd.read_csv('porter_data_1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSRQocOkMSQl"
      },
      "source": [
        "## **2. Data Preprocessing and Feature Engineering** <font color = red>[15 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02uPO8aQfLnn"
      },
      "source": [
        "#### **2.1 Fixing the Datatypes**  <font color = red>[5 marks]</font> <br>\n",
        "The current timestamps are in object format and need conversion to datetime format for easier handling and intended functionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b22Kzjew3rdM"
      },
      "source": [
        "##### **2.1.1** <font color = red>[2 marks]</font> <br>\n",
        "Convert date and time fields to appropriate data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoGkz909IXjv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "15bffbb4-1f67-4dab-879a-4137db1a4932"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   market_id           created_at actual_delivery_time  \\\n",
              "0        1.0  2015-02-06 22:24:17  2015-02-06 23:11:17   \n",
              "1        2.0  2015-02-10 21:49:25  2015-02-10 22:33:25   \n",
              "2        2.0  2015-02-16 00:11:35  2015-02-16 01:06:35   \n",
              "3        1.0  2015-02-12 03:36:46  2015-02-12 04:35:46   \n",
              "4        1.0  2015-01-27 02:12:36  2015-01-27 02:58:36   \n",
              "\n",
              "   store_primary_category  order_protocol  total_items  subtotal  \\\n",
              "0                       4             1.0            4      3441   \n",
              "1                      46             2.0            1      1900   \n",
              "2                      36             3.0            4      4771   \n",
              "3                      38             1.0            1      1525   \n",
              "4                      38             1.0            2      3620   \n",
              "\n",
              "   num_distinct_items  min_item_price  max_item_price  total_onshift_dashers  \\\n",
              "0                   4             557            1239                   33.0   \n",
              "1                   1            1400            1400                    1.0   \n",
              "2                   3             820            1604                    8.0   \n",
              "3                   1            1525            1525                    5.0   \n",
              "4                   2            1425            2195                    5.0   \n",
              "\n",
              "   total_busy_dashers  total_outstanding_orders  distance  \n",
              "0                14.0                      21.0     34.44  \n",
              "1                 2.0                       2.0     27.60  \n",
              "2                 6.0                      18.0     11.56  \n",
              "3                 6.0                       8.0     31.80  \n",
              "4                 5.0                       7.0      8.20  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8055cbdb-f0d3-48bf-b2cb-7a1683abf3c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>market_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>actual_delivery_time</th>\n",
              "      <th>store_primary_category</th>\n",
              "      <th>order_protocol</th>\n",
              "      <th>total_items</th>\n",
              "      <th>subtotal</th>\n",
              "      <th>num_distinct_items</th>\n",
              "      <th>min_item_price</th>\n",
              "      <th>max_item_price</th>\n",
              "      <th>total_onshift_dashers</th>\n",
              "      <th>total_busy_dashers</th>\n",
              "      <th>total_outstanding_orders</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2015-02-06 22:24:17</td>\n",
              "      <td>2015-02-06 23:11:17</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3441</td>\n",
              "      <td>4</td>\n",
              "      <td>557</td>\n",
              "      <td>1239</td>\n",
              "      <td>33.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>34.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2015-02-10 21:49:25</td>\n",
              "      <td>2015-02-10 22:33:25</td>\n",
              "      <td>46</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1900</td>\n",
              "      <td>1</td>\n",
              "      <td>1400</td>\n",
              "      <td>1400</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2015-02-16 00:11:35</td>\n",
              "      <td>2015-02-16 01:06:35</td>\n",
              "      <td>36</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4771</td>\n",
              "      <td>3</td>\n",
              "      <td>820</td>\n",
              "      <td>1604</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2015-02-12 03:36:46</td>\n",
              "      <td>2015-02-12 04:35:46</td>\n",
              "      <td>38</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1525</td>\n",
              "      <td>1</td>\n",
              "      <td>1525</td>\n",
              "      <td>1525</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>31.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2015-01-27 02:12:36</td>\n",
              "      <td>2015-01-27 02:58:36</td>\n",
              "      <td>38</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3620</td>\n",
              "      <td>2</td>\n",
              "      <td>1425</td>\n",
              "      <td>2195</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8055cbdb-f0d3-48bf-b2cb-7a1683abf3c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8055cbdb-f0d3-48bf-b2cb-7a1683abf3c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8055cbdb-f0d3-48bf-b2cb-7a1683abf3c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-de6cbfab-07e5-429c-927d-6601ec5d4f69\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de6cbfab-07e5-429c-927d-6601ec5d4f69')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-de6cbfab-07e5-429c-927d-6601ec5d4f69 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Delivery_time_Data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Convert 'created_at' and 'actual_delivery_time' columns to datetime format\n",
        "\n",
        "Delivery_time_Data.head()\n",
        " Delivery_time_Data['created_at_time_format'] = pd.to_datetime(Delivery_time_Data['created_at'])\n",
        " Delivery_time_Data['actual_delivery_time_format'] = pd.to_datetime(Delivery_time_Data['actual_delivery_time'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1EBPjFc4Qca"
      },
      "source": [
        "##### **2.1.2**  <font color = red>[3 marks]</font> <br>\n",
        "Convert categorical fields to appropriate data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PihPSPhQq1nQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "0ffc3235-0523-40c1-de0e-cbe2ba021a16"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Delivery_time_Data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-204264882474>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert categorical features to category type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDelivery_time_Data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDelivery_time_Data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"created_at\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# finding the unique classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Delivery_time_Data' is not defined"
          ]
        }
      ],
      "source": [
        "# Convert categorical features to category type\n",
        "Delivery_time_Data.info()\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "label_encoder.fit(Delivery_time_Data[\"created_at\"])\n",
        "# finding the unique classes\n",
        "print(list(label_encoder.classes_))\n",
        "print()\n",
        "# values after transforming the categorical column.\n",
        "print(label_encoder.transform(Delivery_time_Data[\"created_at\"]))\n",
        "Delivery_time_Data[\"created_at_Transform\"] = label_encoder.transform(Delivery_time_Data[\"created_at\"])\n",
        "\n",
        "\n",
        "Delivery_time_Data.info()\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "label_encoder.fit(Delivery_time_Data[\"actual_delivery_time\"])\n",
        "# finding the unique classes\n",
        "print(list(label_encoder.classes_))\n",
        "print()\n",
        "# values after transforming the categorical column.\n",
        "print(label_encoder.transform(Delivery_time_Data[\"actual_delivery_time\"]))\n",
        "Delivery_time_Data[\"actual_delivery_time_Transform\"] = label_encoder.transform(Delivery_time_Data[\"actual_delivery_time\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsEGroRFlX8z"
      },
      "source": [
        "#### **2.2 Feature Engineering** <font color = red>[5 marks]</font> <br>\n",
        "Calculate the time taken to execute the delivery as well as extract the hour and day at which the order was placed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KLP0YoIdnPDz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BubGzQyJpHLQ"
      },
      "source": [
        "##### **2.2.1** <font color = red>[2 marks]</font> <br>\n",
        "Calculate the time taken using the features `actual_delivery_time` and `created_at`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBGS4PZJMciZ"
      },
      "outputs": [],
      "source": [
        "# Calculate time taken in minutes\n",
        " Delivery_time_Data['created_at_time_format'] = pd.to_datetime(Delivery_time_Data['created_at'])\n",
        " Delivery_time_Data['actual_delivery_time_format'] = pd.to_datetime(Delivery_time_Data['actual_delivery_time'])\n",
        " Delivery_time_Data['time_taken'] = (Delivery_time_Data['actual_delivery_time_format'] - Delivery_time_Data['created_at_time_format']).dt.total_seconds() / 60\n",
        "sns.distplot(Delivery_time_Data['time_taken'],kde=False)\n",
        "plt.title('time_taken')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngUUAf3XOPAP"
      },
      "source": [
        "##### **2.2.2** <font color = red>[3 marks]</font> <br>\n",
        "Extract the hour at which the order was placed and which day of the week it was. Drop the unnecessary columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwA4O5VtNxQW"
      },
      "outputs": [],
      "source": [
        "# Extract the hour and day of week from the 'created_at' timestamp\n",
        "\n",
        "def extract_date_features(data):\n",
        "    data[\"created_at_time_format_day\"] = data.created_at_time_format.dt.day\n",
        "    data[\"created_at_time_format_hour\"] = data.created_at_time_format.dt.hour\n",
        "    data[\"created_at_time_format_day_name\"] = data.created_at_time_format.dt.day_name()\n",
        "    data[\"created_at_time_format_weekday\"] = data.created_at_time_format.dt.weekday\n",
        "    data['created_at_time_format_day_of_week'] = data.created_at_time_format.dt.day_of_week.astype(int)\n",
        "    data['created_at_time_format_is_weekend'] = np.where(data['day_of_week'].isin([5,6]),1,0)\n",
        "\n",
        "extract_date_features(Delivery_time_Data)\n",
        "Delivery_time_Data.info()\n",
        "\n",
        "\n",
        "\n",
        "def extract_date_features(data):\n",
        "    data[\"actual_delivery_time_format_day\"] = data.actual_delivery_time_format.dt.day\n",
        "    data[\"actual_delivery_time_format_hour\"] = data.actual_delivery_time_format.dt.hour\n",
        "    data[\"actual_delivery_time_format_day_name\"] = data.actual_delivery_time_format.dt.day_name()\n",
        "    data[\"actual_delivery_time_format_weekday\"] = data.actual_delivery_time_format.dt.weekday\n",
        "    data['actual_delivery_time_format_day_of_week'] = data.actual_delivery_time_format.dt.day_of_week.astype(int)\n",
        "    data['actual_delivery_time_format_is_weekend'] = np.where(data['day_of_week'].isin([5,6]),1,0)\n",
        "\n",
        "extract_date_features(Delivery_time_Data)\n",
        "Delivery_time_Data.info()\n",
        "\n",
        "\n",
        "# Create a categorical feature 'isWeekend'\n",
        "\n",
        "# Convert 'Category' column to categorical type\n",
        "Delivery_time_Data['created_at_time_format_is_weekend'] = Delivery_time_Data['created_at_time_format_is_weekend'].astype('category')\n",
        "# Convert 'Category' column to categorical type\n",
        "Delivery_time_Data['actual_delivery_time_format_is_weekend'] = Delivery_time_Data['actual_delivery_time_format_is_weekend'].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgzSO8wyOTbP"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "  Delivery_time_Data.drop(columns=['created_at_time_format_date', 'created_at_time_format_time','created_at_time_format_dayname','created_at_time_format_day_no','actual_delivery_time_format_day_of_week','actual_delivery_time_format_is_weekend'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JJxTsQOFKyl"
      },
      "source": [
        "#### **2.3 Creating training and validation sets** <font color = red>[5 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuyPJMpCFyUL"
      },
      "source": [
        "##### **2.3.1** <font color = red>[2 marks]</font> <br>\n",
        " Define target and input features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVyKFLXTFKRE"
      },
      "outputs": [],
      "source": [
        "# Define target variable (y) and features (X)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# We specify this so that the train and test data set always have the same rows, respectively\n",
        "np.random.seed(0)\n",
        "df_train, df_test = train_test_split(Delivery_time_Data, train_size = 0.7, test_size = 0.3, random_state = 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e56iVNqdF3G8"
      },
      "source": [
        "##### **2.3.2** <font color = red>[3 marks]</font> <br>\n",
        " Split the data into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t7XtNDEF6Pu"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# We specify this so that the train and test data set always have the same rows, respectively\n",
        "np.random.seed(0)\n",
        "df_train, df_test = train_test_split(Delivery_time_Data, train_size = 0.7, test_size = 0.3, random_state = 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQxv96NBAq_y"
      },
      "source": [
        "## **3. Exploratory Data Analysis on Training Data** <font color = red>[20 marks]</font> <br>\n",
        "1. Analyzing the correlation between variables to identify patterns and relationships\n",
        "2. Identifying and addressing outliers to ensure the integrity of the analysis\n",
        "3. Exploring the relationships between variables and examining the distribution of the data for better insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU1baEcRc1-A"
      },
      "source": [
        "#### **3.1 Feature Distributions** <font color = red> [7 marks]</font> <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj7yFI7VJ_va"
      },
      "outputs": [],
      "source": [
        "# Define numerical and categorical columns for easy EDA and data manipulation\n",
        "cat_cols=Delivery_time_Data.select_dtypes(include=['object']).columns\n",
        "num_cols = Delivery_time_Data.select_dtypes(include=np.number).columns.tolist()\n",
        "print(\"Categorical Variables:\")\n",
        "print(cat_cols)\n",
        "print(\"Numerical Variables:\")\n",
        "print(num_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWMFLWKpHE-R"
      },
      "source": [
        "##### **3.1.1** <font color = red>[3 marks]</font> <br>\n",
        "Plot distributions for numerical columns in the training set to understand their spread and any skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M0u5G1YR73_"
      },
      "outputs": [],
      "source": [
        "# Plot distributions for all numerical columns\n",
        "\n",
        "sns.pairplot(Delivery_time_Data)\n",
        "plt.show()\n",
        "sns.distplot(Delivery_time_Data['num_distinct_items'],kde=False)\n",
        "plt.title('num_distinct_items')\n",
        "plt.show()\n",
        "sns.distplot(Delivery_time_Data['total_busy_dashers'],kde=False)\n",
        "plt.title('total_busy_dashers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MtpapIvc9rC"
      },
      "source": [
        "##### **3.1.2** <font color = red>[2 marks]</font> <br>\n",
        "Check the distribution of categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr8loNgMLdrm"
      },
      "outputs": [],
      "source": [
        "# Distribution of categorical columns\n",
        "Delivery_time_Data['colour'].value_counts().plot(kind='bar')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-9pcLxzJZWf"
      },
      "source": [
        "##### **3.1.3** <font color = red>[2 mark]</font> <br>\n",
        "Visualise the distribution of the target variable to understand its spread and any skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiWe2Bl9R7yL"
      },
      "outputs": [],
      "source": [
        "# Distribution of time_taken\n",
        "\n",
        "sns.distplot(Delivery_time_Data['time_taken'],kde=False)\n",
        "plt.title('time_taken')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbxczs61dROZ"
      },
      "source": [
        "#### **3.2 Relationships Between Features** <font color = red>[3 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH81kNkOOvlx"
      },
      "source": [
        "##### **3.2.1** <font color = red>[3 marks]</font> <br>\n",
        "Scatter plots for important numerical and categorical features to observe how they relate to `time_taken`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIBnRHohR799"
      },
      "outputs": [],
      "source": [
        "# Scatter plot to visualise the relationship between time_taken and other features\n",
        "\n",
        "sns.pairplot(Delivery_time_Data)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiWL3cKowfZd"
      },
      "outputs": [],
      "source": [
        "# Show the distribution of time_taken for different hours\n",
        "\n",
        "   # Using displot for individual distributions\n",
        "   sns.displot(Delivery_time_Data, x='time_taken', kde=True)\n",
        "   sns.displot(Delivery_time_Data, x='actual_delivery_time_format_hour', kde=True)\n",
        "   plt.show()\n",
        "\n",
        "   # Using displot for joint distribution\n",
        "   sns.displot(Delivery_time_Data, x='time_taken', y='actual_delivery_time_format_hour', kind='kde')\n",
        "   plt.show()\n",
        "\n",
        "      # Using displot for individual distributions\n",
        "   sns.displot(Delivery_time_Data, x='time_taken', kde=True)\n",
        "   sns.displot(Delivery_time_Data, x='actual_delivery_time_format_hour', kde=True)\n",
        "   plt.show()\n",
        "\n",
        "   # Using displot for joint distribution\n",
        "   sns.displot(Delivery_time_Data, x='time_taken', y='actual_delivery_time_format_hour', kind='kde')\n",
        "   plt.show()\n",
        "\n",
        "   sns.distplot(Delivery_time_Data['created_at_time_format_hour'],kde=False)\n",
        "plt.title('created_at_time_format_hour')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKg6rBljIJFP"
      },
      "source": [
        "#### **3.3 Correlation Analysis** <font color = red>[5 marks]</font> <br>\n",
        "Check correlations between numerical features to identify which variables are strongly related to `time_taken`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyk00sbYfnc0"
      },
      "source": [
        "##### **3.3.1** <font color = red>[3 marks]</font> <br>\n",
        "Plot a heatmap to display correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxrdHdvKR7vy"
      },
      "outputs": [],
      "source": [
        "# Plot the heatmap of the correlation matrix\n",
        "\n",
        "plt.figure(figsize = (16, 10))\n",
        "sns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yuD3RIwffZE"
      },
      "source": [
        "##### **3.3.2** <font color = red>[2 marks]</font> <br>\n",
        "Drop the columns with weak correlations with the target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDZN586gH8R_"
      },
      "outputs": [],
      "source": [
        "# Drop 3-5 weakly correlated columns from training dataset\n",
        "\n",
        "  Delivery_time_Data.drop(columns=['created_at', 'actual_delivery_time','created_at_time_format','actual_delivery_time_format',], axis=1, inplace=True)\n",
        "\n",
        "  cat_cols=Delivery_time_Data.select_dtypes(include=['object']).columns\n",
        "num_cols = Delivery_time_Data.select_dtypes(include=np.number).columns.tolist()\n",
        "print(\"Categorical Variables:\")\n",
        "print(cat_cols)\n",
        "print(\"Numerical Variables:\")\n",
        "print(num_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mZv2rz6lxvc"
      },
      "source": [
        "#### **3.4 Handling the Outliers** <font color = red>[5 marks]</font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdyAT-OhyH3z"
      },
      "source": [
        "##### **3.4.1** <font color = red>[2 marks]</font> <br>\n",
        "Visualise potential outliers for the target variable and other numerical features using boxplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ow3Mowo4R71T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "2b521bfa-f06f-4d94-f615-d5bd7355772a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Delivery_time_Data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3ed4f7a4be1c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming df is your DataFrame and 'column_name' is the column you want to plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m Delivery_time_Data.boxplot(column=['market_id', 'store_primary_category', 'order_protocol', 'total_items', 'num_distinct_items', 'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders', 'distance', 'time_taken']\n\u001b[0m\u001b[1;32m      7\u001b[0m , figsize=(20,10))\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Delivery_time_Data' is not defined"
          ]
        }
      ],
      "source": [
        "# Boxplot for time_taken\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df is your DataFrame and 'column_name' is the column you want to plot\n",
        "Delivery_time_Data.boxplot(column=['market_id', 'store_primary_category', 'order_protocol', 'total_items', 'num_distinct_items', 'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders', 'distance', 'time_taken']\n",
        ", figsize=(20,10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZCaGBKv_stm"
      },
      "source": [
        "##### **3.4.2** <font color = red>[3 marks]</font> <br>\n",
        "Handle outliers present in all columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwQ1A_wZ_X_K"
      },
      "outputs": [],
      "source": [
        "# Handle outliers\n",
        "Delivery_time_Data = Delivery_time_Data[Delivery_time_Data.total_items <=100]\n",
        "Delivery_time_Data.describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Cd2J-LGWaF"
      },
      "source": [
        "## **4. Exploratory Data Analysis on Validation Data** <font color = red>[optional]</font> <br>\n",
        "Optionally, perform EDA on test data to see if the distribution match with the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sN6bG_hTbUE"
      },
      "outputs": [],
      "source": [
        "# Define numerical and categorical columns for easy EDA and data manipulation\n",
        "\n",
        "cat_cols=Delivery_time_Data.select_dtypes(include=['object']).columns\n",
        "num_cols = Delivery_time_Data.select_dtypes(include=np.number).columns.tolist()\n",
        "print(\"Categorical Variables:\")\n",
        "print(cat_cols)\n",
        "print(\"Numerical Variables:\")\n",
        "print(num_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zq16lr0Q9IG"
      },
      "source": [
        "#### **4.1 Feature Distributions**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuoIVgXlQC9y"
      },
      "source": [
        "##### **4.1.1**\n",
        "Plot distributions for numerical columns in the validation set to understand their spread and any skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKgSvKvzG8fv"
      },
      "outputs": [],
      "source": [
        "# Plot distributions for all numerical columns\n",
        "\n",
        "# Let's visualise the data with a scatter plot and the fitted regression line\n",
        "plt.scatter(X_train_lm.iloc[:, 1], y_train)\n",
        "plt.plot(X_train_lm.iloc[:, 1], 0.127 + 0.462*X_train_lm.iloc[:, 1], 'r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrywBQGWQC9z"
      },
      "source": [
        "##### **4.1.2**\n",
        "Check the distribution of categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0CIcl2tHBwp"
      },
      "outputs": [],
      "source": [
        "# Distribution of categorical columns\n",
        "\n",
        "cat_cols=Delivery_time_Data.select_dtypes(include=['object']).columns\n",
        "num_cols = Delivery_time_Data.select_dtypes(include=np.number).columns.tolist()\n",
        "print(\"Categorical Variables:\")\n",
        "print(cat_cols)\n",
        "print(\"Numerical Variables:\")\n",
        "print(num_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_j74bnlQC9z"
      },
      "source": [
        "##### **4.1.3**\n",
        "Visualise the distribution of the target variable to understand its spread and any skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dGfR8MHGtqm"
      },
      "outputs": [],
      "source": [
        "# Distribution of time_taken\n",
        "plt.figure(figsize = (16, 10))\n",
        "sns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki2FI7fsHDgK"
      },
      "source": [
        "#### **4.2 Relationships Between Features**\n",
        "Scatter plots for numerical features to observe how they relate to each other, especially to `time_taken`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lzNPoK4HFnZ"
      },
      "outputs": [],
      "source": [
        "# Scatter plot to visualise the relationship between time_taken and other features\n",
        "\n",
        "plt.figure(figsize = (16, 10))\n",
        "sns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8VoM0XfXWko"
      },
      "source": [
        "#### **4.3** Drop the columns with weak correlations with the target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BnM8w2lXWkp"
      },
      "outputs": [],
      "source": [
        "# Drop the weakly correlated columns from training dataset\n",
        "# Boxplot for time_taken\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df is your DataFrame and 'column_name' is the column you want to plot\n",
        "Delivery_time_Data.boxplot(column=['market_id', 'store_primary_category', 'order_protocol', 'total_items', 'num_distinct_items', 'total_onshift_dashers', 'total_busy_dashers', 'total_outstanding_orders', 'distance', 'time_taken']\n",
        ", figsize=(20,10))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReNN4PyM8enl"
      },
      "source": [
        "## **5. Model Building** <font color = red>[15 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l2XfNF6nc8L"
      },
      "source": [
        "#### **Import Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__fmfT6vQWpd"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import statsmodels\n",
        "import statsmodels.api as sm\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCLIKw5pQiA7"
      },
      "source": [
        "#### **5.1 Feature Scaling** <font color = red>[3 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "newEgSyyQiHK"
      },
      "outputs": [],
      "source": [
        "# Apply scaling to the numerical columns\n",
        "\n",
        "# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\n",
        "num_vars = ['market_id', 'store_primary_category', 'order_protocol', 'total_items', 'subtotal','num_distinct_items','min_item_price','max_item_price','total_onshift_dashers','total_outstanding_orders','distance','time_taken']\n",
        "\n",
        "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXcV5Z_E8tLL"
      },
      "source": [
        "Note that linear regression is agnostic to feature scaling. However, with feature scaling, we get the coefficients to be somewhat on the same scale so that it becomes easier to compare them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bxip-t3Y1MB"
      },
      "source": [
        "#### **5.2 Build a linear regression model** <font color = red>[5 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7jZciTFtric"
      },
      "source": [
        "You can choose from the libraries *statsmodels* and *scikit-learn* to build the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMRpgx_iQYM4"
      },
      "outputs": [],
      "source": [
        "# Create/Initialise the model\n",
        "# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\n",
        "num_vars = ['market_id', 'store_primary_category', 'order_protocol', 'total_items', 'subtotal','num_distinct_items','min_item_price','max_item_price','total_onshift_dashers','total_outstanding_orders','distance','time_taken']\n",
        "\n",
        "df_train[num_vars] = scaler.fit_transform(df_trai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbJVZpMiW8b2"
      },
      "outputs": [],
      "source": [
        "# Train the model using the training data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCQcJtDbW_dG"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_train = df_train.pop('time_taken')\n",
        "X_train = df_train\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Add a constant\n",
        "X_train_lm = sm.add_constant(X_train[['distance']])\n",
        "\n",
        "# Create a first fitted model\n",
        "lr = sm.OLS(y_train, X_train_lm).fit()\n",
        "sns.distplot(Delivery_time_Data['time_taken'],kde=False)\n",
        "plt.title('time_taken')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udw5kE1fXBsR"
      },
      "outputs": [],
      "source": [
        "# Find results for evaluation metrics\n",
        "\n",
        "scaler= MinMaxScaler()\n",
        "num_vars =['market_id','store_primary_category','order_protocol','total_items','subtotal','num_distinct_items','min_item_price','max_item_price','total_onshift_dashers','total_busy_dashers','total_outstanding_orders','distance','time_taken']\n",
        "df_train[num_vars]=scaler.fit_transform(df_train[num_vars])\n",
        "df_train.head()\n",
        "y_train_time_taken = lr_3.predict(X_train_lm)\n",
        "\n",
        "# Plot the histogram of the error terms\n",
        "fig = plt.figure()\n",
        "sns.distplot((y_train - y_train_time_taken), bins = 20)\n",
        "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading\n",
        "plt.xlabel('Errors', fontsize = 18)                         # X-label\n",
        "\n",
        "num_vars =['market_id','store_primary_category','order_protocol','total_items','subtotal','num_distinct_items','min_item_price','max_item_price','total_onshift_dashers','total_busy_dashers','total_outstanding_orders','distance','time_taken']\n",
        "\n",
        "df_test[num_vars] = scaler.transform(df_test[num_vars])\n",
        "# Import LabelEncoder from sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def label_encoding(df):\n",
        "    categorical_columns = df.select_dtypes(include='object').columns\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[categorical_columns] = df[categorical_columns].apply(lambda col: label_encoder.fit_transform(col))\n",
        "\n",
        "label_encoding(Delivery_time_Data)\n",
        "Delivery_time_Data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3-HovybcZKR"
      },
      "source": [
        "[link text](https://)Note that we have 12 (depending on how you select features) training features. However, not all of them would be useful. Let's say we want to take the most relevant 8 features.\n",
        "\n",
        "We will use Recursive Feature Elimination (RFE) here.\n",
        "\n",
        "For this, you can look at the coefficients / p-values of features from the model summary and perform feature elimination, or you can use the RFE module provided with *scikit-learn*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU8OLQ4bnwdr"
      },
      "source": [
        "#### **5.3 Build the model and fit RFE to select the most important features** <font color = red>[7 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4FZMiX11RyI"
      },
      "source": [
        "For RFE, we will start with all features and use\n",
        "the RFE method to recursively reduce the number of features one-by-one.\n",
        "\n",
        "After analysing the results of these iterations, we select the one that has a good balance between performance and number of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub1HgSwl1eiC"
      },
      "outputs": [],
      "source": [
        "# Loop through the number of features and test the model\n",
        "\n",
        "y_test = df_test.pop('time_taken')\n",
        "X_test = df_test\n",
        "# Adding constant variable to test dataframe\n",
        "X_test_m4 = sm.add_constant(X_test)\n",
        "# Creating X_test_m4 dataframe by dropping variables from X_test_m4\n",
        "X_test_m4 = X_test_m4.drop('total_busy_dashers', axis = 1)\n",
        "# Making predictions using the fourth model\n",
        "\n",
        "y_pred_m4 = lr_3.predict(X_test_m4)\n",
        "# Plotting y_test and y_pred to understand the spread\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.scatter(y_test, y_pred_m4)\n",
        "fig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading\n",
        "plt.xlabel('y_test', fontsize = 18)                          # X-label\n",
        "plt.ylabel('y_pred', fontsize = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7p-CAQn3wQE"
      },
      "outputs": [],
      "source": [
        "# Build the final model with selected number of features\n",
        "\n",
        " OLS Regression Results\n",
        "==============================================================================\n",
        "Dep. Variable:             time_taken   R-squared:                       0.834\n",
        "Model:                            OLS   Adj. R-squared:                  0.834\n",
        "Method:                 Least Squares   F-statistic:                 5.620e+04\n",
        "Date:                Wed, 28 May 2025   Prob (F-statistic):               0.00\n",
        "Time:                        08:52:15   Log-Likelihood:             1.8557e+05\n",
        "No. Observations:              123043   AIC:                        -3.711e+05\n",
        "Df Residuals:                  123031   BIC:                        -3.710e+05\n",
        "Df Model:                          11\n",
        "Covariance Type:            nonrobust\n",
        "============================================================================================\n",
        "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
        "--------------------------------------------------------------------------------------------\n",
        "const                        0.0015      0.001      2.128      0.033       0.000       0.003\n",
        "market_id                   -0.0468      0.001    -81.124      0.000      -0.048      -0.046\n",
        "store_primary_category       0.0054      0.001     10.089      0.000       0.004       0.006\n",
        "order_protocol              -0.0635      0.001   -102.564      0.000      -0.065      -0.062\n",
        "subtotal                     0.4784      0.004    116.090      0.000       0.470       0.486\n",
        "num_distinct_items           0.1723      0.003     53.402      0.000       0.166       0.179\n",
        "min_item_price               0.0502      0.006      7.912      0.000       0.038       0.063\n",
        "max_item_price               0.2208      0.006     37.187      0.000       0.209       0.232\n",
        "total_onshift_dashers       -0.8421      0.003   -320.203      0.000      -0.847      -0.837\n",
        "total_busy_dashers          -0.0021   1.59e-05   -129.354      0.000      -0.002      -0.002\n",
        "total_outstanding_orders     1.4425      0.003    547.851      0.000       1.437       1.448\n",
        "distance                     0.5613      0.001    385.174      0.000       0.558       0.564\n",
        "==============================================================================\n",
        "Omnibus:                    23126.342   Durbin-Watson:                   1.997\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            59158.221\n",
        "Skew:                           1.036   Prob(JB):                         0.00\n",
        "Kurtosis:                       5.693   Cond. No.                     2.58e+03\n",
        "==============================================================================\n",
        "\n",
        "Notes:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "[2] The condition number is large, 2.58e+03. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0l_mLL_4OOl"
      },
      "source": [
        "## **6. Results and Inference** <font color = red>[5 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsPGaacJ71mt"
      },
      "source": [
        "#### **6.1 Perform Residual Analysis** <font color = red>[3 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbj7O8rf7SZS"
      },
      "outputs": [],
      "source": [
        "# Perform residual analysis using plots like residuals vs predicted values, Q-Q plot and residual histogram\n",
        "# Calculate the VIFs again for the new model\n",
        "vif = pd.DataFrame()\n",
        "vif['Features'] = X_train_lm.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X_train_lm.values, i) for i in range(X_train_lm.shape[1])]\n",
        "vif['VIF'] = round(vif['VIF'], 2)\n",
        "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
        "vif\n",
        "\n",
        "\tFeatures\tVIF\n",
        "0\tconst\t20.19\n",
        "8\ttotal_onshift_dashers\t11.71\n",
        "9\ttotal_busy_dashers\t11.25\n",
        "10\ttotal_outstanding_orders\t9.89\n",
        "4\tsubtotal\t3.40\n",
        "5\tnum_distinct_items\t3.27\n",
        "7\tmax_item_price\t2.22\n",
        "6\tmin_item_price\t2.15\n",
        "3\torder_protocol\t1.05\n",
        "2\tstore_primary_category\t1.02\n",
        "1\tmarket_id\t1.01\n",
        "11\tdistance\t1.00\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq4g9xPsu4T5"
      },
      "source": [
        "[Your inferences here:]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2-CiCId7_y9"
      },
      "source": [
        "#### **6.2 Perform Coefficient Analysis** <font color = red>[2 marks]</font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2koFJovu-cH"
      },
      "source": [
        "Perform coefficient analysis to find how changes in features affect the target.\n",
        "Also, the features were scaled, so interpret the scaled and unscaled coefficients to understand the impact of feature changes on delivery time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr8EWhg_9QnI"
      },
      "outputs": [],
      "source": [
        "# Compare the scaled vs unscaled features used in the final model\n",
        "\n",
        "\tFeatures\tVIF\n",
        "0\tconst\t20.19\n",
        "8\ttotal_onshift_dashers\t11.71\n",
        "9\ttotal_busy_dashers\t11.25\n",
        "10\ttotal_outstanding_orders\t9.89\n",
        "4\tsubtotal\t3.40\n",
        "5\tnum_distinct_items\t3.27\n",
        "7\tmax_item_price\t2.22\n",
        "6\tmin_item_price\t2.15\n",
        "3\torder_protocol\t1.05\n",
        "2\tstore_primary_category\t1.02\n",
        "1\tmarket_id\t1.01\n",
        "11\tdistance\t1.00\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ5VcQ2G-SOb"
      },
      "source": [
        "Additionally, we can analyse the effect of a unit change in a feature. In other words, because we have scaled the features, a unit change in the features will not translate directly to the model. Use scaled and unscaled coefficients to find how will a unit change in a feature affect the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMHN7r-x-Lp5"
      },
      "outputs": [],
      "source": [
        "# Analyze the effect of a unit change in a feature, say 'total_items'\n",
        "\n",
        "==================================================\n",
        "Dep. Variable:             time_taken   R-squared:                       0.812\n",
        "Model:                            OLS   Adj. R-squared:                  0.811\n",
        "Method:                 Least Squares   F-statistic:                 4.815e+04\n",
        "Date:                Wed, 28 May 2025   Prob (F-statistic):               0.00\n",
        "Time:                        08:25:54   Log-Likelihood:             1.7775e+05\n",
        "No. Observations:              123043   AIC:                        -3.555e+05\n",
        "Df Residuals:                  123031   BIC:                        -3.554e+05\n",
        "Df Model:                          11\n",
        "Covariance Type:            nonrobust\n",
        "============================================================================================\n",
        "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
        "--------------------------------------------------------------------------------------------\n",
        "const                        0.0019      0.001      2.571      0.010       0.000       0.003\n",
        "market_id                   -0.0457      0.001    -74.389      0.000      -0.047      -0.045\n",
        "store_primary_category       0.0049      0.001      8.613      0.000       0.004       0.006\n",
        "order_protocol              -0.0670      0.001   -101.503      0.000      -0.068      -0.066\n",
        "total_items                 -0.2487      0.037     -6.661      0.000      -0.322      -0.175\n",
        "subtotal                     0.4825      0.005    107.191      0.000       0.474       0.491\n",
        "num_distinct_items           0.1876      0.004     49.450      0.000       0.180       0.195\n",
        "min_item_price               0.0482      0.007      7.127      0.000       0.035       0.061\n",
        "max_item_price               0.2061      0.006     31.955      0.000       0.193       0.219\n",
        "total_onshift_dashers       -1.0308      0.002   -441.856      0.000      -1.035      -1.026\n",
        "total_outstanding_orders     1.2967      0.003    511.403      0.000       1.292       1.302\n",
        "distance                     0.5596      0.002    360.369      0.000       0.557       0.563\n",
        "==============================================================================\n",
        "Omnibus:                    22808.828   Durbin-Watson:                   1.994\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            59497.669\n",
        "Skew:                           1.015   Prob(JB):                         0.00\n",
        "Kurtosis:                       5.735   Cond. No.                         302.\n",
        "==============================================================================\n",
        "\n",
        "Notes:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFWJ2s9I_Yeo"
      },
      "source": [
        "Note:\n",
        "The coefficients on the original scale might differ greatly in magnitude from the scaled coefficients, but they both describe the same relationships between variables.\n",
        "\n",
        "Interpretation is key: Focus on the direction and magnitude of the coefficients on the original scale to understand the impact of each variable on the response variable in the original units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClCit1tvKIyE"
      },
      "source": [
        "Include conclusions in your report document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn-wDgoeSiHP"
      },
      "source": [
        "## Subjective Questions <font color = red>[20 marks]</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z7F6yjykZZY"
      },
      "source": [
        "Answer the following questions only in the notebook. Include the visualisations/methodologies/insights/outcomes from all the above steps in your report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVJSi-Q0Cw_r"
      },
      "source": [
        "#### Subjective Questions based on Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_jiT95xTA6q"
      },
      "source": [
        "##### **Question 1.** <font color = red>[2 marks]</font> <br>\n",
        "\n",
        "Are there any categorical variables in the data? From your analysis of the categorical variables from the dataset, what could you infer about their effect on the dependent variable?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvFQvBy3VM9A"
      },
      "source": [
        "\n",
        "\n",
        "**Answer:**\n",
        ">created_at and actual_delivery_time  are the categorial variable in the data which is the time format.\n",
        "so these has to be converted to time object or time format to extract data and time for caluating the tme taken\n",
        " Delivery_time_Data['created_at_time_format'] = pd.to_datetime(Delivery_time_Data['created_at'])\n",
        " Delivery_time_Data['actual_delivery_time_format'] = pd.to_datetime(Delivery_time_Data['actual_delivery_time'])\n",
        " Delivery_time_Data['time_taken'] = (Delivery_time_Data['actual_delivery_time_format'] - Delivery_time_Data['created_at_time_format']).dt.total_seconds() / 60\n",
        "Delivery_time_Data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqPxxtWEY3_W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDSRymTJTHCW"
      },
      "source": [
        "##### **Question 2.** <font color = red>[1 marks]</font> <br>\n",
        "What does `test_size = 0.2` refer to during splitting the data into training and test sets?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRBCcZvoVx-r"
      },
      "source": [
        "**Answer:**\n",
        ">In ML course , test_size=0.2 during data splitting indicates that 20% of the dataset will be used for testing the model, while the remaining 80% will be used for training. This is a common split ratio, though other ratios like 70/30 or 60/40 are also used. The test set helps evaluate the model's performance on unseen data, preventing overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_afbTV8Y5-F"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEVX57VbTJBP"
      },
      "source": [
        "##### **Question 3.** <font color = red>[1 marks]</font> <br>\n",
        "Looking at the heatmap, which one has the highest correlation with the target variable?  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewPqz4yLWBzR"
      },
      "source": [
        "**Answer:**\n",
        ">Highest correleaction based on heat map is distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLy_-8F5Y69c"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg-6E-N-TKyS"
      },
      "source": [
        "##### **Question 4.** <font color = red>[2 marks]</font> <br>\n",
        "What was your approach to detect the outliers? How did you address them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPUDtsRGWLZl"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        ">To identify and address outliers, we can use visual inspection and statistical methods. For visualization, I used box plots, histograms, and scatter plots to observe deviations from the expected data distribution. Statistically, I applied the interquartile range (IQR) method and z-score analysis to pinpoint extreme values. Outliers were then addressed by either trimming or removing them, quantile-based flooring and capping, or mean/median imputation, depending on the nature of the data and the analysis objectives.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVyJFcT2Y7U8"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvh9CLFnTMhO"
      },
      "source": [
        "##### **Question 5.** <font color = red>[2 marks]</font> <br>\n",
        "Based on the final model, which are the top 3 features significantly affecting the delivery time?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-DDpZcCWUun"
      },
      "source": [
        "**Answer:**\n",
        ">Based on the final model the major one impactong the delivery time or time taken are total oustanding order distance and subtotal\n",
        "\n",
        "const                        0.0015      0.001      2.128      0.033       0.000       0.003\n",
        "market_id                   -0.0468      0.001    -81.124      0.000      -0.048      -0.046\n",
        "store_primary_category       0.0054      0.001     10.089      0.000       0.004       0.006\n",
        "order_protocol              -0.0635      0.001   -102.564      0.000      -0.065      -0.062\n",
        "subtotal                     0.4784      0.004    116.090      0.000       0.470       0.486\n",
        "num_distinct_items           0.1723      0.003     53.402      0.000       0.166       0.179\n",
        "min_item_price               0.0502      0.006      7.912      0.000       0.038       0.063\n",
        "max_item_price               0.2208      0.006     37.187      0.000       0.209       0.232\n",
        "total_onshift_dashers       -0.8421      0.003   -320.203      0.000      -0.847      -0.837\n",
        "total_busy_dashers          -0.0021   1.59e-05   -129.354      0.000      -0.002      -0.002\n",
        "total_outstanding_orders     1.4425      0.003    547.851      0.000       1.437       1.448\n",
        "distance                     0.5613      0.001    385.174      0.000       0.558       0.564"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVCrLjhTY74h"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBLH_lA5C4jy"
      },
      "source": [
        "#### General Subjective Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MJGDVyiTOyr"
      },
      "source": [
        "##### **Question 6.** <font color = red>[3 marks]</font> <br>\n",
        "Explain the linear regression algorithm in detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZc1QX8RW_Pa"
      },
      "source": [
        "**Answer:**\n",
        ">Linear regression is a supervised machine learning algorithm that predicts a continuous numerical value by modeling the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship, meaning the output changes at a constant rate as the input changes, and represents this relationship with a straight line or a hyperplane in multiple dimensions.\n",
        "Here's a more detailed explanation:\n",
        "1. Supervised Learning: Linear regression, like other regression algorithms, is a supervised learning method. This means it learns from labeled data, where both the input (independent variable) and the corresponding output (dependent variable) are known.\n",
        "2. Predicting Continuous Values: It's specifically used for predicting continuous numerical values, such as predicting house prices, sales, or temperatures.\n",
        "3. Linear Relationship Assumption: The core principle of linear regression is that it assumes a linear relationship between the input features (independent variables) and the target variable (dependent variable). This means the relationship can be represented by a straight line (in simple linear regression) or a hyperplane in multiple-dimensional spaces (in multiple linear regression).\n",
        "4. Finding the Best Fit Line: The algorithm aims to find the line (or hyperplane) that best fits the data points, minimizing the distance between the predicted values and the actual values.\n",
        "5. Cost Function and Minimization: The \"best fit\" line is determined by minimizing a cost function, which measures the difference between the predicted values and the actual values. A common cost function is the Mean Squared Error (MSE), which calculates the average of the squared differences.\n",
        "6. Multiple Linear Regression: When there are multiple independent variables, it's called multiple linear regression. The model then becomes a linear combination of the input features, with each feature having a weight that represents its influence on the target.\n",
        "7. Applications: Linear regression is widely used in various fields for:\n",
        "Predicting: Forecasting sales, predicting house prices, estimating market trends, etc.\n",
        "Understanding relationships: Identifying the relationship between variables and their effects on each other.\n",
        "In summary, linear regression is a powerful and versatile algorithm for predicting continuous values by finding the best-fitting linear relationship between input features and the target variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0MCb30NY8UE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db_7gqf8TQTk"
      },
      "source": [
        "##### **Question 7.** <font color = red>[2 marks]</font> <br>\n",
        "Explain the difference between simple linear regression and multiple linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1jsR8htXD8j"
      },
      "source": [
        "**Answer:**\n",
        ">Simple linear regression uses one independent variable to predict a dependent variable, while multiple linear regression uses two or more independent variables to predict the same dependent variable. Simple linear regression models a linear relationship between one predictor and an outcome, whereas multiple regression allows for more complex models of an outcome based on multiple factors.\n",
        "\n",
        "Simple Linear Regression:\n",
        "\n",
        "One Independent Variable:\n",
        "It examines the relationship between a single predictor variable and the outcome variable.\n",
        "Simpler Model:\n",
        "Easier to interpret and implement, with a straightforward linear relationship.\n",
        "Prediction Focused:\n",
        "Useful for situations where a single factor is believed to strongly influence the outcome.\n",
        "\n",
        "Multiple Linear Regression:\n",
        "Two or More Independent Variables:\n",
        "It considers multiple predictor variables simultaneously to understand their combined influence on the outcome.\n",
        "More Complex Model:\n",
        "Can capture more complex relationships between variables and improve predictive accuracy.\n",
        "Can Control for Variables:\n",
        "Can be used to account for the effects of multiple factors, isolating the impact of individual variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnSGZEltY8ss"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT6ivEEnTSEs"
      },
      "source": [
        "##### **Question 8.** <font color = red>[2 marks]</font> <br>\n",
        "What is the role of the cost function in linear regression, and how is it minimized?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2PaCL-FXSSn"
      },
      "source": [
        "**Answer:**\n",
        ">In linear regression, the cost function quantifies the difference between predicted and actual values, acting as a measure of model performance. Minimizing this cost function, often through algorithms like gradient descent, refines the model's parameters to produce more accurate predictions.\n",
        "\n",
        "\n",
        "Role of the Cost Function:\n",
        "Performance Metric:\n",
        "The cost function provides a numerical score reflecting how well the model is performing, with lower values indicating better performance.\n",
        "\n",
        "Error Indicator:\n",
        "It measures the discrepancy between the model's predictions and the true values, highlighting areas where the model needs improvement.\n",
        "\n",
        "Optimization Guide:\n",
        "By minimizing the cost function, the model can adjust its parameters to reduce the error and improve its predictive ability.\n",
        "\n",
        "\n",
        "Minimizing the Cost Function:\n",
        "Gradient Descent:\n",
        "This iterative optimization algorithm adjusts the model's parameters (e.g., slope and intercept in a linear regression) based on the direction of the cost function's gradient.\n",
        "\n",
        "\n",
        "Learning Rate:\n",
        "The learning rate controls the size of the steps taken during each iteration of gradient descent, balancing the need for quick convergence with the risk of overshooting the minimum.\n",
        "\n",
        "Iteration:\n",
        "The process of updating parameters is repeated until the cost function converges to a minimum, indicating that the model has found its optimal parameters.\n",
        "Common Cost Function in Linear Regression: Mean Squared Error (MSE):\n",
        "Calculation:\n",
        "MSE calculates the average of the squared differences between predicted and actual values.\n",
        "Interpretation:\n",
        "It penalizes larger errors more significantly than smaller ones, ensuring that the model's predictions are as close as possible to the true values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIKB_W0FY9QM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZIb5hbMCCVY"
      },
      "source": [
        "##### **Question 9.** <font color = red>[2 marks]</font> <br>\n",
        "Explain the difference between overfitting and underfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8kn4c-7CEjP"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        ">Overfitting and underfitting are two common challenges in machine learning model training. Overfitting occurs when a model learns the training data too well, including noise and outliers, leading to poor generalization on new, unseen data. Underfitting, on the other hand, occurs when a model is too simple to capture the underlying patterns in the data, resulting in poor performance on both training and new data.\n",
        "Overfitting:\n",
        "Definition:\n",
        "A model that is too complex and captures noise and irrelevant details in the training data, leading to high accuracy on training data but poor accuracy on unseen data.\n",
        "Causes:\n",
        "Using a model with too many parameters, training for too long, and having a small training dataset.\n",
        "Characteristics:\n",
        "High accuracy on the training data but low accuracy on new data, high variance, and low bias.\n",
        "Example:\n",
        "A model that memorizes the exact examples in the training data but fails to generalize to new data points that are slightly different.\n",
        "Underfitting:\n",
        "Definition: A model that is too simple and cannot capture the underlying patterns in the data, resulting in poor performance on both training and new data.\n",
        "Causes: Using a model with too few parameters, training for too short a time, and not having enough features.\n",
        "Characteristics: Low accuracy on both training and new data, low variance, and high bias.\n",
        "Example: A linear regression model trying to fit a curved dataset.\n",
        "How to address overfitting and underfitting:\n",
        "Overfitting:\n",
        "Increase the amount of training data: This can help the model generalize better by exposing it to a wider range of examples.\n",
        "Use regularization techniques: These methods penalize complex models, encouraging them to find simpler solutions.\n",
        "Simplify the model: Reduce the number of parameters or features used by the model.\n",
        "Early stopping: Monitor the model's performance on a validation set and stop training when the performance starts to decline.\n",
        "Underfitting:\n",
        "Use a more complex model: Increase the number of parameters or features used by the model.\n",
        "Train for a longer period: Give the model more time to learn the patterns in the data.\n",
        "Add more features: Include more relevant features in the model.\n",
        "Reduce regularization: Reduce the penalty on complex models, allowing them to fit the data more closely.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PWIs-suCMEr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os7JPKHwArn7"
      },
      "source": [
        "##### **Question 10.** <font color = red>[3 marks]</font> <br>\n",
        "How do residual plots help in diagnosing a linear regression model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqxU8GSkAubl"
      },
      "source": [
        "**Answer:**\n",
        ">Residual plots are crucial for diagnosing linear regression models because they visually represent the discrepancies between observed and predicted values, revealing potential issues with the model's fit. By examining the scatter of points on the residual plot, one can identify if the model is adequately specified, if it violates assumptions about error distribution, or if there are influential data points.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MueJxkvUIII3",
        "02uPO8aQfLnn",
        "b22Kzjew3rdM",
        "u1EBPjFc4Qca",
        "-JJxTsQOFKyl",
        "v0Cd2J-LGWaF",
        "fCLIKw5pQiA7",
        "2bxip-t3Y1MB",
        "mn-wDgoeSiHP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}